{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82d206f",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<img src=\"../docs/assets/app-logo/logo-transparent-bw.png\">\n",
    "\n",
    "## *An AI agent that stands for **S**tructured **M**emory & **A**nalysis with **R**easoning and **T**ools*.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d089f",
   "metadata": {},
   "source": [
    "# **Project Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8062a4a",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "This project focuses on developing an modular **AI Agent for advanced compositional reasoning via semantic memory retrieval and tool integration** that will be benchmarked against the **GAIA-Level-1 dataset**.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08218b",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "To achieve this, we are combining **Retrieval-Augmented Generation** (RAG) and external module-use capabilities with a **Large Language Model** (LLM) as its core guided by a structured **system prompt**.\n",
    "\n",
    "The main technologies and infrastructure underpinning this system are:\n",
    "\n",
    "- **LangChain**  \n",
    "  *Framework for integrating LLMs with external data, tools, APIs, etc.*\n",
    "\n",
    "- **LangGraph**  \n",
    "  *Toolkit for building stateful AI workflows with graph-based control.*\n",
    "\n",
    "- **Supabase**  \n",
    "  *Vector database for storing and retrieving semantic embeddings.*\n",
    "\n",
    "- **External APIs**:  \n",
    "  - **Tavily Search**  \n",
    "  - **Wikipedia**  \n",
    "  - **ArXiv**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562446ba",
   "metadata": {},
   "source": [
    "# **Chapter 1: Analyzing the GAIA Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88ab0a",
   "metadata": {},
   "source": [
    "## **1.1 Data Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fe501",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The **GAIA** (General AI Alignment) dataset is designed as a comprehensive benchmark for evaluating the reasoning skills of artificial intelligence systems, particularly those that interact with real-world environments or perform complex tasks. \n",
    "\n",
    "It is structured into three progressive levels, each increasing in complexity: \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align: center;\">Level</th>\n",
    "      <th style=\"text-align: center;\">Steps</th>\n",
    "      <th style=\"text-align: center;\">Tool Usage</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center;\">Level 1</td>\n",
    "      <td style=\"text-align: center;\">1-5</td>\n",
    "      <td style=\"text-align: center;\">One</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center;\">Level 2</td>\n",
    "      <td style=\"text-align: center;\">5-10</td>\n",
    "      <td style=\"text-align: center;\">Multiple</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center;\">Level 3</td>\n",
    "      <td style=\"text-align: center;\">Unlimited</td>\n",
    "      <td style=\"text-align: center;\">Advanced</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "<p align=\"justify\">\n",
    "\n",
    "The dataset consists of questions, final answers, and annotated thinking traces. Metadata such as task IDs, tool usage, and temporal constraints enable detailed analysis and agent training.\n",
    "\n",
    "In this project we use a curated subset of the GAIA-Level-1 collection which offers a balanced set of examples that require multi-hop logic throughout  diverse domains while maintaining computational feasibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597c4f5",
   "metadata": {},
   "source": [
    "> <p align=\"justify\">\n",
    "\n",
    "> ℹ️ <i>Human annotators achieve an average accuracy of 92% on GAIA queries, while current advanced AI systems, such as GPT-4 equipped with plugins, reach only about 15% accuracy</i>.\n",
    "> </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691a07f",
   "metadata": {},
   "source": [
    "## **1.2 Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3fcb2",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The initial phase involves loading the *metadata.jsonl* file which contains the challenge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b92fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata.jsonl file\n",
    "import json\n",
    "\n",
    "with open('../src/agent/data/metadata.jsonl', 'r') as jsonl_file:\n",
    "    json_list = list(jsonl_file)\n",
    "\n",
    "json_QA = []\n",
    "for json_str in json_list:\n",
    "    json_data = json.loads(json_str)\n",
    "    json_QA.append(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec5ec4",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Here it is a random sample to provide an initial view into the format and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd06c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Task ID: 0bdb7c40-671d-4ad1-9ce3-986b159c0ddc\n",
      "Question: In NASA's Astronomy Picture of the Day on 2006 January 21, two astronauts are visible, with one appearing much smaller than the other. As of August 2023, out of the astronauts in the NASA Astronaut Group that the smaller astronaut was a member of, which one spent the least time in space, and how many minutes did he spend in space, rounded to the nearest minute? Exclude any astronauts who did not spend any time in space. Give the last name of the astronaut, separated from the number of minutes by a semicolon.\n",
      "Level: 3\n",
      "Final Answer: White; 5876\n",
      "Annotator Metadata: \n",
      "  ├── Steps: \n",
      "  │      ├── 1. Use search engine to search for \"NASA's Astronomy Picture of the Day 2006 January 21\".\n",
      "  │      ├── 2. Open the link to the image.\n",
      "  │      ├── 3. Read the explanation to find that the image is of astronaut Charles \"Pete\" Conrad reflected in the helmet of astronaut Alan Bean.\n",
      "  │      ├── 4. Observe that the smaller astronaut in the image is the one reflected in the other's helmet, so the smaller astronaut must be Charles \"Pete\" Conrad.\n",
      "  │      ├── 5. Go to the Wikipedia page for Charles \"Pete\" Conrad.\n",
      "  │      ├── 6. Search for \"Astronaut Group\" to find that Conrad was a member of NASA Astronaut Group 2.\n",
      "  │      ├── 7. Open the Wikipedia pages for each member of NASA Astronaut Group 2.\n",
      "  │      ├── 8. For those who are not deceased, go to View history and select the latest version of their Wikipedia page as of August 2023.\n",
      "  │      ├── 9. Compare the times listed in the infobox of each astronaut's Wikipedia page under \"Time in space\", observing that Ed White has the least time in space with 4d 01h 56m, but also that Elliott See does not have a listed \"Time in space\".\n",
      "  │      ├── 10. Read through Elliot See's Wikipedia article to find that he died in an accident before his first space flight, so he should be excluded, making Ed White's 4d 01h 56m the least amount of time in space.\n",
      "  │      ├── 11. Convert 4d 01h 56m to minutes: 4d * 24h/d * 60m/h + 1h * 60m/h + 56m = 5,876m\n",
      "  │      ├── 12. Format the final answer as specified: White; 5,876\n",
      "  ├── Number of steps: 12\n",
      "  ├── How long did this take?: 10\n",
      "  ├── Tools:\n",
      "  │      ├── 1. Web browser\n",
      "  │      ├── 2. Search engine\n",
      "  │      ├── 3. Image processing tools\n",
      "  │      ├── 4. Calculator\n",
      "  └── Number of tools: 4\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Select a random sample\n",
    "import random\n",
    "\n",
    "random_samples = random.sample(json_QA, 1)\n",
    "for sample in random_samples:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Task ID: {sample['task_id']}\")\n",
    "    print(f\"Question: {sample['Question']}\")\n",
    "    print(f\"Level: {sample['Level']}\")\n",
    "    print(f\"Final Answer: {sample['Final answer']}\")\n",
    "    print(f\"Annotator Metadata: \")\n",
    "    print(f\"  ├── Steps: \")\n",
    "    for step in sample['Annotator Metadata']['Steps'].split('\\n'):\n",
    "        print(f\"  │      ├── {step}\")\n",
    "    print(f\"  ├── Number of steps: {sample['Annotator Metadata']['Number of steps']}\")\n",
    "    print(f\"  ├── How long did this take?: {sample['Annotator Metadata']['How long did this take?']}\")\n",
    "    print(f\"  ├── Tools:\")\n",
    "    for tool in sample['Annotator Metadata']['Tools'].split('\\n'):\n",
    "        print(f\"  │      ├── {tool}\")\n",
    "    print(f\"  └── Number of tools: {sample['Annotator Metadata']['Number of tools']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbc94e",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Knowing the type of interrogations that are being asked and the responses that are expected to be given, we can begin to build the agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe179b6",
   "metadata": {},
   "source": [
    "# **Chapter 2: Forging the Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658027fa",
   "metadata": {},
   "source": [
    "## **2.1 Agent's Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11261f67",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Its objective is to enhance the agent's ability to recall past knowledge by providing relevant historical information.\n",
    "\n",
    "This memory system is built using **Supabase** as a vector storage where GAIA records are embedded using **HuggingFace's sentence transformers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6dbdec",
   "metadata": {},
   "source": [
    "### **2.1.1 Vector Database Set Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fe079",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The process begins with creating and setting up the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e47967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build a vector database: https://python.langchain.com/docs/integrations/vectorstores/supabase/\n",
    "import os\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase.client import Client, create_client\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")  # dim=768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c08135",
   "metadata": {},
   "source": [
    "> <p align=\"justify\">\n",
    "\n",
    ">  ⬇️ Copy and run this SQL script in your <b>Supabase SQL Editor</b> proyect ⬇️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e7590",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- 1️⃣ Clean up existing objects\n",
    "\n",
    "DROP FUNCTION IF EXISTS public.match_documents_langchain(vector, integer);\n",
    "DROP TABLE IF EXISTS public.documents;\n",
    "\n",
    "-- 2️⃣ Install vector extension\n",
    "\n",
    "DROP EXTENSION IF EXISTS vector;\n",
    "CREATE SCHEMA IF NOT EXISTS extensions;\n",
    "CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA extensions;\n",
    "\n",
    "-- 3️⃣ Create documents table\n",
    "\n",
    "CREATE TABLE public.documents (\n",
    "  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
    "  content TEXT,\n",
    "  metadata JSONB,\n",
    "  embedding extensions.vector(768)\n",
    ");\n",
    "\n",
    "-- 4️⃣ Enable Row Level Security (RLS)\n",
    "\n",
    "ALTER TABLE public.documents ENABLE ROW LEVEL SECURITY;\n",
    "\n",
    "-- 5️⃣ Add open access policy\n",
    "\n",
    "CREATE POLICY \"Allow all access\"\n",
    "ON public.documents\n",
    "FOR ALL\n",
    "USING (true)\n",
    "WITH CHECK (true);\n",
    "\n",
    "-- 6️⃣ Create vector search function\n",
    "\n",
    "CREATE OR REPLACE FUNCTION public.match_documents_langchain(\n",
    "  query_embedding extensions.vector(768),\n",
    "  match_count INT DEFAULT 5\n",
    ")\n",
    "RETURNS TABLE (\n",
    "  id UUID,\n",
    "  content TEXT,\n",
    "  metadata JSONB,\n",
    "  similarity FLOAT\n",
    ")\n",
    "LANGUAGE sql\n",
    "STABLE\n",
    "SET search_path = public, extensions\n",
    "AS $$\n",
    "  SELECT\n",
    "    id,\n",
    "    content,\n",
    "    metadata,\n",
    "    1 - (embedding <#> query_embedding) AS similarity\n",
    "  FROM\n",
    "    public.documents\n",
    "  ORDER BY\n",
    "    embedding <#> query_embedding\n",
    "  LIMIT match_count;\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc2ddc",
   "metadata": {},
   "source": [
    "### **2.1.1 Data Ingestion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d8548",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The next step involves transforming our set of Q&A into document embeddings to store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf096ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the metadata.jsonl's questions and answers into a list of document\n",
    "docs = []\n",
    "for sample in json_QA:\n",
    "    content = f\"Question : {sample['Question']}\\n\\nFinal answer : {sample['Final answer']}\"\n",
    "    doc = {\n",
    "        \"content\" : content,\n",
    "        \"metadata\" : {\n",
    "            \"source\" : sample['task_id']\n",
    "        },\n",
    "        \"embedding\" : embeddings.embed_query(content),\n",
    "    }\n",
    "    docs.append(doc)\n",
    "\n",
    "# Upload the documents to the vector database\n",
    "try:\n",
    "    response = (\n",
    "        supabase.table(\"documents\")\n",
    "        .insert(docs)\n",
    "        .execute()\n",
    "    )\n",
    "except Exception as exception:\n",
    "    print(\"Error inserting data into database:\", exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0506d",
   "metadata": {},
   "source": [
    "### **2.1.2 Retriever Builder**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136327a",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Finally, a retriever is created to enable semantic search across the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1bd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add items to vector database\n",
    "vector_store = SupabaseVectorStore(\n",
    "    client=supabase,\n",
    "    embedding= embeddings,\n",
    "    table_name=\"documents\",\n",
    "    query_name=\"match_documents_langchain\",\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ad8f",
   "metadata": {},
   "source": [
    "## **2.2 Tool Arsenal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239c446",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Its objective is to extend the agent's capabilities beyond its internal knowledge by providing external resources that allow it to tackle complex challenges and diverse reasoning challenges.\n",
    "\n",
    "These tools are built using **LangChain** to integrate the LLM with external modules and APIs, including mathematical operations and query processing utilities like **Tavily Search**, **Wikipedia**, and **ArXiv**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33771c",
   "metadata": {},
   "source": [
    "### **2.2.1 Mathematical Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c1bb3",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Basic arithmetic operations form the foundation of quantitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252bc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader, WikipediaLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import StructuredTool, Tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ---------- Pydantic schemas for math tools ----------\n",
    "class MathInput(BaseModel):\n",
    "    a: int = Field(description=\"First number\")\n",
    "    b: int = Field(description=\"Second number\")\n",
    "\n",
    "# ---------- Math tools ----------\n",
    "def multiply_fn(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "multiply = StructuredTool.from_function(\n",
    "    func=multiply_fn,\n",
    "    name=\"multiply\",\n",
    "    description=\"Multiply two numbers\",\n",
    "    args_schema=MathInput\n",
    ")\n",
    "\n",
    "def add_fn(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "add = StructuredTool.from_function(\n",
    "    func=add_fn,\n",
    "    name=\"add\",\n",
    "    description=\"Add two numbers\",\n",
    "    args_schema=MathInput\n",
    ")\n",
    "\n",
    "def subtract_fn(a: int, b: int) -> int:\n",
    "    return a - b\n",
    "\n",
    "subtract = StructuredTool.from_function(\n",
    "    func=subtract_fn,\n",
    "    name=\"subtract\",\n",
    "    description=\"Subtract two numbers\",\n",
    "    args_schema=MathInput\n",
    ")\n",
    "\n",
    "def divide_fn(a: int, b: int) -> float:\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero.\")\n",
    "    return a / b\n",
    "\n",
    "divide = StructuredTool.from_function(\n",
    "    func=divide_fn,\n",
    "    name=\"divide\",\n",
    "    description=\"Divide two numbers\",\n",
    "    args_schema=MathInput\n",
    ")\n",
    "\n",
    "def modulus_fn(a: int, b: int) -> int:\n",
    "    return a % b\n",
    "\n",
    "modulus = StructuredTool.from_function(\n",
    "    func=modulus_fn,\n",
    "    name=\"modulus\",\n",
    "    description=\"Modulus of two numbers\",\n",
    "    args_schema=MathInput\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa5e64",
   "metadata": {},
   "source": [
    "### **2.2.2 Knowledge Retrieval Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fa51a",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Information retrieval capabilities are essential for accessing both structured and unstructured data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ff0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Wikipedia search ----------\n",
    "def wiki_search_fn(input: str) -> str:\n",
    "    search_docs = WikipediaLoader(query=input, load_max_docs=2).load()\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "    return formatted\n",
    "\n",
    "wiki_search = Tool.from_function(\n",
    "    func=wiki_search_fn,\n",
    "    name=\"wiki_search\",\n",
    "    description=\"Search Wikipedia for a query and return up to 2 results.\"\n",
    ")\n",
    "\n",
    "# ---------- Web search ----------\n",
    "def web_search_fn(input: str) -> str:\n",
    "    search_results = TavilySearchResults(max_results=3).invoke(input)\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, result in enumerate(search_results):\n",
    "        url = result.get('url', 'No URL')\n",
    "        title = result.get('title', 'No Title')\n",
    "        content = result.get('content', 'No Content')\n",
    "        \n",
    "        formatted_doc = f'<Document source=\"{url}\" title=\"{title}\"/>\\n{content}\\n</Document>'\n",
    "        formatted_results.append(formatted_doc)\n",
    "    \n",
    "    return \"\\n\\n---\\n\\n\".join(formatted_results)\n",
    "\n",
    "web_search = Tool.from_function(\n",
    "    func=web_search_fn,\n",
    "    name=\"web_search\",\n",
    "    description=\"Search Tavily for a query and return up to 3 results.\"\n",
    ")\n",
    "\n",
    "# ---------- ArXiv search ----------\n",
    "def arxiv_search_fn(input: str) -> str:\n",
    "    try:\n",
    "        search_docs = ArxivLoader(query=input, load_max_docs=3).load()\n",
    "        formatted = \"\\n\\n---\\n\\n\".join(\n",
    "            [\n",
    "                f'<Document source=\"{doc.metadata.get(\"source\", \"arXiv\")}\" title=\"{doc.metadata.get(\"title\", \"\")}\" entry_id=\"{doc.metadata.get(\"entry_id\", \"\")}\"/>\\n{doc.page_content[:1000]}...\\n</Document>'\n",
    "                for doc in search_docs\n",
    "            ]\n",
    "        )\n",
    "        return formatted\n",
    "    except Exception as e:\n",
    "        return f\"Error searching arXiv: {str(e)}\"\n",
    "\n",
    "arxiv_search = Tool.from_function(\n",
    "    func=arxiv_search_fn,\n",
    "    name=\"arxiv_search\",\n",
    "    description=\"Search Arxiv for a query and return up to 3 results.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e51a4",
   "metadata": {},
   "source": [
    "## **2.3 System Prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad3ae9",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> \n",
    "\n",
    "Its objective is to establish clear thought process patterns for consistent and methodical problem-solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a reasoning assistant that answers questions step by step using tools when needed.\n",
    "\n",
    "CRITICAL: You MUST follow the exact format specified below. Do not deviate from this structure.\n",
    "\n",
    "Your tasks:\n",
    "- Break down your thinking into clear numbered steps that explain your thinking\n",
    "- Use internal knowledge and the available tools to solve the queries\n",
    "- Specify each tool used and why you chose it\n",
    "- End with a direct final reply\n",
    "\n",
    "AVAILABLE TOOLS: You have access to multiply, add, subtract, divide, modulus, wiki_search, web_search, and arxiv_search. Choose the most appropriate tool for each job.\n",
    "\n",
    "==========================\n",
    "MANDATORY FORMAT - Follow this EXACTLY:\n",
    "\n",
    "Steps:\n",
    "1. [IDENTIFY] :             State what you need to find or decide\n",
    "2. [USE] :                  Specify the tool you will use and justify why\n",
    "3. [<ANY ACCURATE VERB>] :  Perform your actions step-by-step\n",
    "4. [RESULT] :               Present the final outcome from your deduction\n",
    "\n",
    "\n",
    "Final Answer:\n",
    "Your direct, concise response\n",
    "\n",
    "==========================\n",
    "\n",
    "EXAMPLES OF PROPER FORMAT:\n",
    "\n",
    "Example 1:\n",
    "Steps:\n",
    "1. [IDENTIFY] : Find the Fahrenheit equivalent of 25°C\n",
    "2. [USE] : Use the formula F = (C × 9/5) + 32 for conversion\n",
    "3. [MULTIPLY] : Calculate 25 × 9 = 225\n",
    "4. [DIVIDE] : Calculate 225 ÷ 5 = 45\n",
    "5. [ADD] : Add 45 + 32 = 77\n",
    "6. [RESULT] : The temperature is 77°F\n",
    "\n",
    "Final Answer:\n",
    "77°F\n",
    "\n",
    "Example 2:\n",
    "Steps:\n",
    "1. [IDENTIFY] : Determine the capital city of Australia\n",
    "2. [USE] : Use web search to get knowledge about Australian geography\n",
    "3. [RECALL] : The capital is Canberra, chosen as a compromise between Sydney and Melbourne\n",
    "4. [RESULT] : Canberra is the official capital city\n",
    "\n",
    "Final Answer:\n",
    "Canberra\n",
    "\n",
    "==========================\n",
    "\n",
    "REQUIREMENTS:\n",
    "\n",
    "> FORMAT RULES:\n",
    "    - Use the exact headers \"Steps:\" and \"Final Answer:\" without any markdown formatting.\n",
    "    - Number each step sequentially: 1, 2, 3, etc.\n",
    "    - Format each step as: [ACTION VERB] : [explanation]\n",
    "    - No markdown symbols anywhere\n",
    "\n",
    "> TOOL INTEGRATION:\n",
    "    - Mathematical tools: multiply, add, subtract, divide, modulus (arithmethic)\n",
    "    - Knowledge tools: web_search (current info), wiki_search (facts), arxiv_search (academic)\n",
    "\n",
    "==========================\n",
    "\n",
    "FINAL REMINDER:\n",
    "Explain WHY you make each decision and HOW you solve the problem step by step.\n",
    "\"\"\"\n",
    "\n",
    "# ---------- System Message ----------\n",
    "sys_msg = SystemMessage(content=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cdf02",
   "metadata": {},
   "source": [
    "## **2.4 Large Language Model (LLM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35cac4",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "Its objective is to act as the agent's central reasoning engine. It is in charge of processing inputs, dynamically selecting appropriate resources during decision-making and generating replies.\n",
    "\n",
    "The selected LLM on this ocassion is **ChatGroq** (*qwen/qwen3-32b*). All tools programmatically bound to it for dynamic functionality leverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24f36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# ---------- LLM ----------\n",
    "llm = ChatGroq(model=\"qwen/qwen3-32b\", temperature=0)\n",
    "\n",
    "# ---------- Tools list ----------\n",
    "tools = [\n",
    "    multiply,\n",
    "    add,\n",
    "    subtract,\n",
    "    divide,\n",
    "    modulus,\n",
    "    wiki_search,\n",
    "    web_search,\n",
    "    arxiv_search\n",
    "]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c57c2",
   "metadata": {},
   "source": [
    "# **Chapter 3: Agent Workflow Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f605d9f",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The agent's operational flow is guided by a framework called **LangGraph** that enables sophisticated state management and conditional routing.\n",
    "\n",
    "The pipeline consists of three primary nodes, each one serving a distinct role in the solution generation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47215dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Nodes\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "        return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    \n",
    "def retriever(state: MessagesState):\n",
    "    similar_question = vector_store.similarity_search(state[\"messages\"][0].content)\n",
    "    example_msg = HumanMessage(\n",
    "        content=f\"Here I provide a similar question and answer for reference: \\n\\n{similar_question[0].page_content}\",\n",
    "    )\n",
    "    return {\"messages\": [sys_msg] + state[\"messages\"] + [example_msg]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"retriever\", retriever)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"retriever\")\n",
    "builder.add_edge(\"retriever\", \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b108810",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "In summary, the process kicks off with the retriever pulling in relevant contextual examples to enrich the input. This enriched context is then passed to the assistant, which begins reasoning over it. As the rationalization unfolds, the assistant can call on external tools when needed, seamlessly merging their outputs to refine and complete its response.\n",
    "\n",
    "The workflow unfolds as follows:\n",
    "\n",
    "- **Retriever Node:**  \n",
    "  *The retriever locates semantically related questions from the memory database upon receiving a request to get contextual examples to enhance the setting.*\n",
    "\n",
    "- **Assistant Node:**  \n",
    "  *The assistant integrates the enriched context — combining the system prompt, the original query and fetched examples. It decides whether to respond directly or trigger a callable operation.*\n",
    "\n",
    "- **Tools Node:**  \n",
    "  *The tools execute specific tasks as needed with their outputs seamlessly fed back to the assistant to support following further considerations.*\n",
    "\n",
    "\n",
    "This iterative approach enables the agent to engage in multi-step deliberation by gradually building toward a comprehensive solution while maintaining transparency throughout its decision-making process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f765ba7",
   "metadata": {},
   "source": [
    "# **Chapter 4: Validation and Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03220bd6",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "We've successfully assembled all our vital components!\n",
    "\n",
    "To ensure everything functions as intended before deploying it on complex challenges, it is essential to conduct a systematic validation of each module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc02640",
   "metadata": {},
   "source": [
    "## **4.1 Comprehensive Tool Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb0607",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The following test cases demonstrate the agent’s capabilities across different cognitive domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f4a84",
   "metadata": {},
   "source": [
    "### **4.1.1 Mathematical Analysis Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a32e8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:\n",
      "1. [IDENTIFY] : Calculate the sum of 25 and 17\n",
      "2. [USE] : Use the add function for basic arithmetic\n",
      "3. [ADD] : Perform 25 + 17 = 42\n",
      "4. [RESULT] : The sum is 42\n",
      "\n",
      "Final Answer:\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "question = \"What is 25 + 17?\"  # Math tool\n",
    "messages = [HumanMessage(content=question)]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0b8dc",
   "metadata": {},
   "source": [
    "### **4.1.2 Knowledge Base Retrieval Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34f6de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:\n",
      "1. [IDENTIFY] : Find the name of the machine Alan Turing proposed to break the Enigma code as documented on Wikipedia.\n",
      "2. [USE] : Use wiki_search to query Wikipedia for precise historical records on Turing's contributions to breaking the Enigma code.\n",
      "3. [CALL] : Execute the search with the query \"Alan Turing Enigma code machine\".\n",
      "4. [RESULT] : Wikipedia states that Turing designed the \"Bombe,\" an electromechanical device used to decipher Enigma-encrypted messages during World War II.\n",
      "\n",
      "Final Answer:\n",
      "The Bombe\n"
     ]
    }
   ],
   "source": [
    "question = \"According to Wikipedia, what was the name of the machine Alan Turing proposed to break the Enigma code?\"  # Wikipedia\n",
    "messages = [HumanMessage(content=question)]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a95fe",
   "metadata": {},
   "source": [
    "### **4.1.3 Real-Time Information Access Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e32cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:\n",
      "1. [IDENTIFY] : Gather recent advancements in AI technologies or innovations from credible sources.\n",
      "2. [USE] : Use web_search to find up-to-date information on recent AI developments.\n",
      "3. [SEARCH] : Execute query \"latest AI technologies 2024 innovations\" to retrieve current trends.\n",
      "4. [ANALYZE] : Review search results for key themes like generative AI, multimodal models, efficiency breakthroughs, and industry applications.\n",
      "5. [RESULT] : Synthesize findings into a concise summary of major innovations.\n",
      "\n",
      "Final Answer:\n",
      "Recent AI advancements include multimodal models (e.g., Google's Gemini), efficient inference techniques (e.g., quantization), AI-driven drug discovery, and ethical frameworks for responsible AI. Notable innovations also involve reinforcement learning in robotics and open-source large language models like Meta's Llama 3.\n"
     ]
    }
   ],
   "source": [
    "question = \"Summarize the latest AI technologies or innovations\" # Web search\n",
    "messages = [HumanMessage(content=question)]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790de0aa",
   "metadata": {},
   "source": [
    "### **4.1.4 Academic Literature Search Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05dafd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:\n",
      "1. [IDENTIFY] : Retrieve arXiv papers related to quantum computing\n",
      "2. [USE] : Use arxiv_search to find relevant academic papers on quantum computing\n",
      "3. [SEARCH] : Execute arxiv_search with query \"quantum computing\"\n",
      "4. [RESULT] : Found 3 relevant papers including \"The Rise of Quantum Internet Computing\" (arXiv:2208.00733v1), \"Unconventional Quantum Computing Devices\" (arXiv:quant-ph/0003151v1), and \"Geometrical perspective on quantum states\" (arXiv:1311.4939v1)\n",
      "\n",
      "Final Answer:\n",
      "Three arXiv papers on quantum computing were found:\n",
      "1. arXiv:2208.00733v1 - \"The Rise of Quantum Internet Computing\" (August 2022)\n",
      "2. arXiv:quant-ph/0003151v1 - \"Unconventional Quantum Computing Devices\" (March 2000)\n",
      "3. arXiv:1311.4939v1 - \"Geometrical perspective on quantum states\" (November 2013)\n"
     ]
    }
   ],
   "source": [
    "question = \"Find arXiv papers on quantum computing\"  # ArXiv\n",
    "messages = [HumanMessage(content=question)]\n",
    "result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43c134a",
   "metadata": {},
   "source": [
    "# **Chapter 5:  Conclusion and Future Perspectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d3aed",
   "metadata": {},
   "source": [
    "## **5.1 Project Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b8b7c",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The agent demonstrates significant improvements over baseline LLMs by incorporating methodical task resolution approaches with expanded information retrieval and specialized operational modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ddb84",
   "metadata": {},
   "source": [
    "## **5.2 Future Directions and AI Agent Trends**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6066f94",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "\n",
    "The AI landscape is rapidly evolving toward more sophisticated systems with emphasis on **Explainable AI** (XAI) integration. Modern systems must provide transparent decision pathways and interpretable reasoning processes—our structured methodology supports this essential requirement as understandability becomes crucial for trust, regulatory compliance and responsible deployment.\n",
    "\n",
    "Furthermore, emerging trends include **multi-agent collaborative systems** where specialized entities contribute unique expertise to collective troubleshooting through domain-specific capabilities and continuously adapt and optimize their own performance.\n",
    "\n",
    "The future lies in systems that explain their thinking and enhance human intelligence rather than replace it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509f191",
   "metadata": {},
   "source": [
    "> <br>\n",
    "> <p style=\"text-align: center;\"><b><i>The future belongs to systems that think alongside us, not for us.</i></b></p>\n",
    "> <br>\n",
    "> <br>\n",
    "> <p style=\"text-align: center;\"> <i>The global AI agents market size was valued at USD 5.43 billion in 2024 and is expected to hit around USD 236.03 billion by 2034, growing at a CAGR of 45.82% AI Market Size to Hit USD 236.03 Billion by 2034 — a 43x growth that signals we're not just building better tools, but architecting the next evolution of human-machine collaboration</i></p>\n",
    "> <br>\n",
    "> <br>\n",
    "> <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
